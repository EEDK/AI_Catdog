{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "# DOG AND CAT 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "import PIL\n",
    "import shutil\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data_zip_dir = './dataset/dogs-vs-cats-redux-kernels-edition'\n",
    "train_zip_dir = os.path.join(data_zip_dir, 'train.zip')\n",
    "test_zip_dir = os.path.join(data_zip_dir, 'test.zip')\n",
    "\n",
    "\"\"\"\n",
    "압축 해제 \n",
    "\"\"\"\n",
    "\n",
    "with zipfile.ZipFile(train_zip_dir, 'r') as z:\n",
    "    z.extractall()\n",
    "with zipfile.ZipFile(test_zip_dir, 'r') as z:\n",
    "    z.extractall()\n",
    "train_dir = os.path.join(os.getcwd(), 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'test')\n",
    "\n",
    " \n",
    "train_set_dir = os.path.join(train_dir, 'train')\n",
    "valid_set_dir = os.path.join(train_dir, 'valid')\n",
    "test_set_dir = os.path.join(train_dir, 'test')\n",
    "\n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "\n",
    "print('set folders')\n",
    "\"\"\"\n",
    "train / test 폴더 생성 \n",
    "\"\"\"\n",
    "train_dir = os.path.join(os.getcwd(), 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'test')\n",
    " \n",
    "train_set_dir = os.path.join(train_dir, 'train')\n",
    "os.mkdir(train_set_dir)\n",
    "valid_set_dir = os.path.join(train_dir, 'valid')\n",
    "os.mkdir(valid_set_dir)\n",
    "test_set_dir = os.path.join(train_dir, 'test')\n",
    "os.mkdir(test_set_dir)\n",
    " \n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "\n",
    "for dog, cat in zip(dog_files[:10000], cat_files[:10000]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(train_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(train_set_dir, cat)\n",
    "    shutil.move(src, dst)\n",
    "    \n",
    "for dog, cat in zip(dog_files[10000:11250], cat_files[10000:11250]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(valid_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(valid_set_dir, cat)\n",
    "    shutil.move(src, dst)\n",
    "    \n",
    "for dog, cat in zip(dog_files[11250:12500], cat_files[11250:12500]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(test_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(test_set_dir, cat)\n",
    "    shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f'the number of train set : {len(os.listdir(train_set_dir))}')\n",
    "print(f'the number of validn set : {len(os.listdir(valid_set_dir))}')\n",
    "print(f'the number of test set : {len(os.listdir(test_set_dir))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 Class 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, root, mode='train', transform=None):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.transform=transform\n",
    "        \n",
    "        if 'cat' in files[0]:\n",
    "            self.label = 0\n",
    "        else:\n",
    "            self.label = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(os.path.join(self.root, self.files[index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            return img, np.array([self.label])\n",
    "        else:\n",
    "            return img, self.files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.RandomCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224,244)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dog_dataset = CustomDataset(dog_files[:10000], train_set_dir, transform=train_transform)\n",
    "train_cat_dataset = CustomDataset(cat_files[:10000], train_set_dir, transform=train_transform)\n",
    "valid_dog_dataset = CustomDataset(dog_files[10000:11250], valid_set_dir, transform=test_transform)\n",
    "valid_cat_dataset = CustomDataset(cat_files[10000:11250], valid_set_dir, transform=test_transform)\n",
    "test_dog_dataset = CustomDataset(dog_files[11250:], test_set_dir, transform=test_transform)\n",
    "test_cat_dataset = CustomDataset(cat_files[11250:], test_set_dir, transform=test_transform)\n",
    " \n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dog_dataset, train_cat_dataset])\n",
    "valid_dataset = torch.utils.data.ConcatDataset([valid_dog_dataset, valid_cat_dataset])\n",
    "test_dataset = torch.utils.data.ConcatDataset([test_dog_dataset, test_cat_dataset])\n",
    "\n",
    "\n",
    "print(f'number of train dataset : {len(train_dataset)}')\n",
    "print(f'number of valid dataset : {len(valid_dataset)}')\n",
    "print(f'number of test dataset : {len(test_dataset)}')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = iter(train_loader).__next__()\n",
    "classes = {0:'cat', 1:'dog'}\n",
    "fig = plt.figure(figsize=(16,24))\n",
    "for i in range(24):\n",
    "    a = fig.add_subplot(4,6,i+1)\n",
    "    a.set_title(classes[labels[i].item()])\n",
    "    a.axis('off')\n",
    "    a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))\n",
    "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "summary(model, input_size=(3,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, epochs, train_loader, valid_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for train_x, train_y in train_loader:\n",
    "            model.train()\n",
    "            train_x, train_y = train_x.to(device), train_y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(train_x)\n",
    "            loss = criterion(pred, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            train_correct += y_pred.eq(train_y.cpu()).int().sum()\n",
    "        \n",
    "        # validation data check\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_correct = 0\n",
    "        for valid_x, valid_y in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_x, valid_y = valid_x.to(device), valid_y.to(device).float()\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            valid_correct += y_pred.eq(valid_y.cpu()).int().sum()\n",
    "        \n",
    "        train_acc = train_correct/len(train_loader.dataset)\n",
    "        valid_acc = valid_correct/len(valid_loader.dataset)\n",
    "        \n",
    "        print(f'{time.time() - start:.3f}sec : [Epoch {epoch+1}/{epochs}] -> train loss: {train_loss/len(train_loader):.4f}, train acc: {train_acc*100:.3f}% / valid loss: {valid_loss/len(valid_loader):.4f}, valid acc: {valid_acc*100:.3f}%')\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss/len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_correct = 0\n",
    "    \n",
    "    plt.plot(train_losses, label='loss')\n",
    "    plt.plot(train_accuracies, label='accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('train loss and accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(valid_losses, label='loss')\n",
    "    plt.plot(valid_accuracies, label='accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('valid loss and accuracy')\n",
    "    plt.show()\n",
    "\n",
    "def eval(model, criterion, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        losses = 0\n",
    "        for test_x, test_y in test_loader:\n",
    "            test_x, test_y = test_x.to(device), test_y.to(device).float()\n",
    "            pred = model(test_x)\n",
    "            loss = criterion(pred, test_y)\n",
    "            \n",
    "            y_pred = pred.cpu()\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            \n",
    "            losses += loss.item()\n",
    "            correct += y_pred.eq(test_y.cpu()).int().sum()\n",
    "    print(f'eval loss: {losses/len(test_loader):.4f}, eval acc: {correct/len(test_loader.dataset)*100:.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    " \n",
    "fit(model, criterion, optimizer, 10, train_loader, valid_loader)\n",
    "eval(model, criterion, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyeonHaeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d4ea8edb1a92ac115b7ebac9c9ea0b8e7cd9e9f0333d86e680b1626844b5d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
