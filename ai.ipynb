{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "# DOG AND CAT 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import PIL\n",
    "import shutil\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain / test 폴더 생성 \\n\\ntrain_dir = os.path.join(os.getcwd(), 'train')\\ntest_dir = os.path.join(os.getcwd(), 'test')\\n \\ntrain_set_dir = os.path.join(train_dir, 'train')\\nos.mkdir(train_set_dir)\\nvalid_set_dir = os.path.join(train_dir, 'valid')\\nos.mkdir(valid_set_dir)\\ntest_set_dir = os.path.join(train_dir, 'test')\\nos.mkdir(test_set_dir)\\n \\ndog_files = [f'dog.{i}.jpg' for i in range(12500)]\\ncat_files = [f'cat.{i}.jpg' for i in range(12500)]\\n\\nfor dog, cat in zip(dog_files[:10000], cat_files[:10000]):\\n    src = os.path.join(train_dir, dog)\\n    dst = os.path.join(train_set_dir, dog)\\n    shutil.move(src, dst)\\n    src = os.path.join(train_dir, cat)\\n    dst = os.path.join(train_set_dir, cat)\\n    shutil.move(src, dst)\\n    \\nfor dog, cat in zip(dog_files[10000:11250], cat_files[10000:11250]):\\n    src = os.path.join(train_dir, dog)\\n    dst = os.path.join(valid_set_dir, dog)\\n    shutil.move(src, dst)\\n    src = os.path.join(train_dir, cat)\\n    dst = os.path.join(valid_set_dir, cat)\\n    shutil.move(src, dst)\\n    \\nfor dog, cat in zip(dog_files[11250:12500], cat_files[11250:12500]):\\n    src = os.path.join(train_dir, dog)\\n    dst = os.path.join(test_set_dir, dog)\\n    shutil.move(src, dst)\\n    src = os.path.join(train_dir, cat)\\n    dst = os.path.join(test_set_dir, cat)\\n    shutil.move(src, dst)\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data_zip_dir = './dataset/dogs-vs-cats-redux-kernels-edition'\n",
    "train_zip_dir = os.path.join(data_zip_dir, 'train.zip')\n",
    "test_zip_dir = os.path.join(data_zip_dir, 'test.zip')\n",
    "\n",
    "\"\"\"\n",
    "압축 해제 \n",
    "\n",
    "with zipfile.ZipFile(train_zip_dir, 'r') as z:\n",
    "    z.extractall()\n",
    "with zipfile.ZipFile(test_zip_dir, 'r') as z:\n",
    "    z.extractall()\n",
    "\"\"\"\n",
    "train_dir = os.path.join(os.getcwd(), 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'test')\n",
    "\n",
    " \n",
    "train_set_dir = os.path.join(train_dir, 'train')\n",
    "valid_set_dir = os.path.join(train_dir, 'valid')\n",
    "test_set_dir = os.path.join(train_dir, 'test')\n",
    "\n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "\"\"\"\n",
    "train / test 폴더 생성 \n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'test')\n",
    " \n",
    "train_set_dir = os.path.join(train_dir, 'train')\n",
    "os.mkdir(train_set_dir)\n",
    "valid_set_dir = os.path.join(train_dir, 'valid')\n",
    "os.mkdir(valid_set_dir)\n",
    "test_set_dir = os.path.join(train_dir, 'test')\n",
    "os.mkdir(test_set_dir)\n",
    " \n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "\n",
    "for dog, cat in zip(dog_files[:10000], cat_files[:10000]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(train_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(train_set_dir, cat)\n",
    "    shutil.move(src, dst)\n",
    "    \n",
    "for dog, cat in zip(dog_files[10000:11250], cat_files[10000:11250]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(valid_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(valid_set_dir, cat)\n",
    "    shutil.move(src, dst)\n",
    "    \n",
    "for dog, cat in zip(dog_files[11250:12500], cat_files[11250:12500]):\n",
    "    src = os.path.join(train_dir, dog)\n",
    "    dst = os.path.join(test_set_dir, dog)\n",
    "    shutil.move(src, dst)\n",
    "    src = os.path.join(train_dir, cat)\n",
    "    dst = os.path.join(test_set_dir, cat)\n",
    "    shutil.move(src, dst)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train set : 20000\n",
      "the number of validn set : 2500\n",
      "the number of test set : 2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f'the number of train set : {len(os.listdir(train_set_dir))}')\n",
    "print(f'the number of validn set : {len(os.listdir(valid_set_dir))}')\n",
    "print(f'the number of test set : {len(os.listdir(test_set_dir))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 Class 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files, root, mode='train', transform=None):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.transform=transform\n",
    "        \n",
    "        if 'cat' in files[0]:\n",
    "            self.label = 0\n",
    "        else:\n",
    "            self.label = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(os.path.join(self.root, self.files[index]))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            return img, np.array([self.label])\n",
    "        else:\n",
    "            return img, self.files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train dataset : 20000\n",
      "number of valid dataset : 2500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'type' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumber of train dataset : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_dataset)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumber of valid dataset : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(valid_dataset)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumber of test dataset : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(test_dataset)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'type' has no len()"
     ]
    }
   ],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.RandomCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224,244)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dog_dataset = CustomDataset(dog_files[:10000], train_set_dir, transform=train_transform)\n",
    "train_cat_dataset = CustomDataset(cat_files[:10000], train_set_dir, transform=train_transform)\n",
    "valid_dog_dataset = CustomDataset(dog_files[10000:11250], valid_set_dir, transform=test_transform)\n",
    "valid_cat_dataset = CustomDataset(cat_files[10000:11250], valid_set_dir, transform=test_transform)\n",
    "test_dog_dataset = CustomDataset(dog_files[11250:], test_set_dir, transform=test_transform)\n",
    "test_cat_dataset = CustomDataset(cat_files[11250:], test_set_dir, transform=test_transform)\n",
    " \n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dog_dataset, train_cat_dataset])\n",
    "valid_dataset = torch.utils.data.ConcatDataset([valid_dog_dataset, valid_cat_dataset])\n",
    "test_dataset = torch.utils.data.ConcatDataset([test_dog_dataset, test_cat_dataset])\n",
    "\n",
    "\n",
    "print(f'number of train dataset : {len(train_dataset)}')\n",
    "print(f'number of valid dataset : {len(valid_dataset)}')\n",
    "print(f'number of test dataset : {len(test_dataset)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyeonHaeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d4ea8edb1a92ac115b7ebac9c9ea0b8e7cd9e9f0333d86e680b1626844b5d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
